## 1. 개발동기
- 알고리즘 구현 부분에 있어, 교육 내용을 많이 활용하였기 때문에 교육생 여러분들이 쉽게 이해할 수 있을거라 생각합니다. 이번 프로젝트를 통해서 이루고 싶었던 한가지가 있었습니다. 가장 중요한 것은 데이터를 위한 모델이 아닌 실생활에서 공감하는 문제를 해결하는 것이었지만, 그 뿐만 아니라 단순히 복잡하고 화려한 모델을 구현하는 것이 아닌 데이터를 손수 얻고 탐색하는 일련의 과정을 이겨내보고, 배운 것을 꼭 활용해보자는 것 또한 꼭 하고자 다짐한 부분이었습니다. 다른 분들의 모델들을 보면 훨씬 멋있는 딥러닝 모델들을 활용해 프로젝트를 진행한 것들을 볼 수 있었는데요, 회귀분석이 머신러닝의 시작을 여는 비교적 단순한 방법론이라 현실 문제 해결에 적용할 수 있을까 많은 의문이 들었지만 구현해나가면서 개선방안 등을 떠올리며 회귀분석의 중요성을 경험하였습니다.
- 중고책이라는 주제를 선정하게 된 것은 얼마전 대학교 과방에서 대청소를 하는 것을 보고 부터였습니다. 사물함마다 남겨진 수많은 중고책들이 버려지는 것을 볼 수 있었는데요, 이런 중고책들이 중고거래로 활발히 거래됨에도 불구하고 버려지는 것이 환경적으로나 경제적으로 큰 문제라 느꼈습니다.
- 어떻게 하면 이렇게 충분한 가치가 있지만 버려지는 중고책을 재활용할 수 있을까 고민했고, 중고책을 자동으로 매입할 수 있도록 하는 서비스가 있다면 앞서말한 문제점들을 해결할 수 있을 것이라 판단했습니다.
- 중고책 매입 자동화를 위해서는, 우선 중고책에 대해 적정가격을 알아야합니다. 따라서 중고책의 적정가격(이 프로젝트에서는 동치관계인 할인율)을 예측하는 프로젝트를 진행해봤습니다!

## 2. 사용기술

- 1-1) 웹크롤링: 웹+크롤링은 웹에서 필요한 데이터를 끌고오는(크롤링) 기술입니다. 웹크롤링을 도와주는 다양한 프레임워크가 존재하는데요, 저는 동적 웹페이지의 크롤링이 가능한 Selenium을 배우고, 활용했습니다. 동적 웹페이지란 다음과 같이 스크롤을 내림에 따라 바뀌는 것처럼 동적으로 반응하는 웹페이지를 의미합니다.
	
	![동적 웹페이지 소개](https://blog.kakaocdn.net/dn/bKeKQq/btrcecovrXM/sTseDgkGf61f8ZNBKE6qT0/img.gif)
	
- 1-2) Selenium: 셀레니움은 크롬 창을 띄우고, 웹페이지의 객체들에 대한 주소값을 활용해 데이터를 긁어올 수 있도록 돕는 프레임워크입니다. 마치 사람이 드래그해 Ctrl+C -> Ctrl+V하는 것과 같은 작업을 자동화할 수 있다고 생각하면 됩니다.
	
	![셀레니움 소개](http://workingwithpython.com/wp-content/uploads/2020/03/%EC%85%80%EB%A0%88%EB%8B%88%EC%9B%80%EC%9C%BC%EB%A1%9C-HTML-%EB%8B%A4%EB%A3%A8%EA%B8%B0_01-2.gif)
	
- 1-3) 데이터 수집: 대학생들이 흔히 중고책을 거래하는 플랫폼인 '에브리타임'의 중고책 거래 배너에서 책의 거래정보를 하나씩 크롤링하도록 자동화하였습니다.
	
	![중고책 거래 소개](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfaoQh%2FbtqEdx6QguJ%2FbmBIuKqQ7VKuTDzNADaIb0%2Fimg.jpg)


- 2) sklearn을 활용한 회귀분석과 변수중요도 파악
 엘리스 AI,SW의 머신러닝교육에서 배운 sckit-learn 라이브러리 및 이를 활용한 linear regression을 진행했습니다. 나아가 해당 라이브러리에서 제공하는 다른 회귀분석 방법론인 DecisionTree(의사결정나무)를 활용해 회귀분석을 진행해 보았습니다.

## 3. 포트폴리오 성과
### 3-1. EDA를 통한 인사이트 얻기(1):
- 웹크롤링을 통해 확보한 데이터프레임에서, 판매완료가 된 책들에 대해 상위 판매량 순으로 조회 및 그래프 시각화를 진행해보았습니다. 분명한 특징이 존재했습니다. 상위 5개는 대학 전교생이 들어야 하는 필수교양 교과목에 대한 수업 교과서였고, 다음 5개는 전교생의 70%를 차지하는 이공계열 학생이 필수로 들어야하는 전공필수 교과목에 대한 교과서였습니다. 이렇게 거래가 활발한 책들을 추려서 상위 10개 중고책에 할인율(== 중고책 가격)을 분석해봤습니다. 

	![상위거래중고책조회](https://cdn-api.elice.io/api-attachment/attachment/0a75855c618c4258983b736c6ecdb42b/image.png)
	
### 3-1. EDA를 통한 인사이트 얻기(2):
- 추가로 이러한 도서가 거래되는 특징 또한 파악할 수 있었습니다. 가장 많은 거래가 있었던 '글이 삶이다'이라는 책에 대해 월별로 시계열 거래량을 시각화한 결과, 매년 학기가 시작하는 3월과 9월에 주기적으로 거래량이 폭등하는 것을 볼 수 있었습니다.
	
	![상위1개중고책 월별 거래량 시각화](https://cdn-api.elice.io/api-attachment/attachment/87e3f9da50794bb4aaa42789d1a65469/image.png)
	
### 3-1. EDA를 통한 인사이트 얻기(3):
- 마지막으로, 책이 출간된 이후로 얼마나 지났는지에 따라 중고책의 할인율이 달라지지 않을까 생각했습니다. 이를 검증하고자 거래량 상위 10개 중고책에 대해, 출판일로부터 거래등록일까지의 개월수 차이에 따른 중고책 할인율을 시계열 그래프로 확인해보았습니다.
	
	![월별할인율시계열](https://cdn-api.elice.io/api-attachment/attachment/cd5a802753974c1b888b187986d099e2/image.png)
	
	출판일로부터 개월수가 늘수록 할인율이 높아지는(저렴해지는) 경향성을 볼 수 있지만, 조금 들쑥날쑥해 연간으로 다시금 확인해보았습니다.
	
	![연별할인율시계열](https://cdn-api.elice.io/api-attachment/attachment/65870389729945899f42d59e024f366c/image.png)
	
	2년까지는 중고책이 저렴해지다가, 이후로는 할인율이 큰 변동없이 진행되는 것을 볼 수 있습니다. 예외적으로 출판된지 7년이 지난 책은 비싸게 팔리는 것을 볼 수 있는데, 이는 수요에 비해 공급이 줄어서 높은 가격(적은 할인율)이 형성되기 때문이라 생각해볼 수 있습니다. 물론 이러한 책들의 거래량이 많지 않기 때문에 성급한 일반화의 오류일 수 있어, 이들에 대해서는 추후 부가적인 EDA를 통해 점검해볼 사항입니다.
	
	결과적으로, 자세하지만 민감한(변동성이 큰) 월별 vs. 보다 강건(robust)한 예측이 가능하지만 너무 단순한 연간 -> 이 둘의 단점은 상쇄하고 장점을 수용할 수 있도록, 출시후 분기별(3개월 단위)로 구분한 변수를 생성해 이를 X feature로 활용하고자 하였습니다. 분기별로 시계열 그래프를 시각화한 결과는 아래와 같습니다.
	
	![robust한 분기별 할인율 시각화](https://cdn-api.elice.io/api-attachment/attachment/0ae65c86d985420a80e1a28dbab17b9a/image.png)
	
	9분기 이후로는 큰 변화가 없는 것을 볼 수 있습니다. 따라서 9분기 이후는 분기값을 동일하게 보고 회귀분석을 진행하는 것으로 EDA를 마무리하였습니다. 출시 4분기째에는 할인율이 감소하는 것을 볼 수 있는데요, 이는 1년(4분기) 후에 신입생이 들어옴으로써 거래량이 느는 것과 더불어, 신입생이라 책을 보다 합리적으로 구매하지 못하는 경우가 다수 있기에 이러한 현상이 발생한다 예상해볼 수 있습니다.
	
	![9분기 이후 병합한 할인율](https://cdn-api.elice.io/api-attachment/attachment/28ff804ebd804bf593e1e2e5998cdd97/image.png)
	
### 3-2. 회귀분석 수행
- 출시이후누적분기수를 X값, 이외에도 필기흔적, 밑줄흔적, 겉표지상태, 이름기입여부, 페이지변색, 페이지훼손 여부를 더미변수로 활용했습니다(크롤링한 데이터입니다). Y값으로는 할인율을 설정해, 예측 모델을 제작해본 결과, test(검증용) 데이터셋에 대해 MSE(Mean Squared Error) = 0.03, MAE(Mean Absolute Error) = 0.12인 매우 유의미한 회귀분석 예측 모델을 완성할 수 있었습니다.

- 나아가 각 X feature에 의해 중고책의 가격을 형성하는 영향력을 feature_importances_라는 메서드를 활용해 아래와 같이 확인했습니다. 앞서 EDA를 수행한 결과에 부합하듯, 출시이후 얼마나 시간이 지났는지가 중고책 할인율을 결정하는 매우 중요한 변수였습니다. 이어서 필기흔적, 이름기입, 페이지 훼손 여부 등이 중고책 할인율에 설명력을 갖는 것을 볼 수 있었습니다.

![중요변수 확인](https://cdn-api.elice.io/api-attachment/attachment/0ff08aa027f14a15b1e150728bcb15ae/image.png)

- 의사결정나무를 활용한 회귀분석 결과 또한 유사한 MSE, MAE 값을 가졌습니다. 이를 graphviz라는 라이브러리를 활용해 시각화한 결과는 pdf로 첨부하였습니다. 의사결정나무의 분기에서 왼쪽은 True(예), 오른쪽은 False(아니오)로 나뉩니다. 값들을 잘 살펴보면, 출시이후 누적반기수가 적을수록(최신본일수록) 할인율이 작음을 볼 수 있습니다. 나머지는 혼동이 올 수도 있지만, 더미변수로 0 또는 1을 나타내도록 변경되었기 때문에, '필기흔적_없음 <= 0.5'은 '필기흔적_없음 == 0', 즉 필기흔적이 연필이나 볼펜으로 있다는 것을 의미합니다. 오른쪽 두번째 레이어의 '필기흔적_없음 == 0'이 True일 때(왼쪽 분기), 필기흔적이 있어 할인율이 높아지고 '필기흔적_없음 == 0'이 False일 때(오른쪽 분기), 필기흔적이 없으므로 깨끗한 책의 상품가치가 높아 할인율이 낮아지는 것을 볼 수 있습니다. 이는 상품이 상등급일수록 가격 방어가 가능하다는 직관적인 인식과 맞아떨어집니다.

- 마지막으로 할인율을 구간(band,밴드)로 나눠서 분류모델을 만들어도 좋을 것 같다는 생각에 할인율을 0-20%, 20-40%, ... , 80-100%의 총 5개 구간으로 나눠서 Decision Tree를 통한 분류모델 또한 만들어보았습니다. 아쉽게도 Accuracy가 0.652라는 값을 가져 좋은 성능을 보여주지는 못했습니다. 이는 추가적인 EDA를 통해 구간을 보다 적절히 나눔으로써 성능이 개선될 수 있다고 생각합니다. 


## 4. 느낀점

- 지금까지는 데이터가 정제되고 주어지는, toy dataset을 활용하거나 주어진 코드 예제를 그대로 따라하는 수준에서 멈췄던 것 같습니다. 하지만 엘리스의 AISW 교육내용과 더불어, 데이터 크롤링을 독학해 찾아가며 데이터셋을 만들어 나가고 궁극적으로는 정말 해결하고자 했던 문제의식을 한꺼풀씩 벗겨나가는 과정을 겪고 나니 짧은 시간동안 많은 성장을 할 수 있었습니다. 엘리스의 프로젝트 경진대회를 통해 이러한 완결성을 갖는 경험의 중요성을 크게 느꼈습니다. 

## 5. 업데이트 계획
- 발전가능성: 비단 중고책뿐만이 아니라, 당근마켓 등 중고거래에도 이러한 할인율(중고가격) 예측을 수행함으로써 적정가격에 중고품을 거래함으로써 판매자와 구매자 모두 win-win이 되도록 할 수 있습니다. 이러한 적정가격을 제대로 예측한다면 매입을 자동화할 수 있고, 유동성이 낮은 품목들은 보관하다가 판매함으로써 물건이 헛되이 버려지지 않게 할 수 있습니다. 가치를 알지 못해 버려지는 수많은 물건들을 활용할 수 있도록 함에 있어 이러한 가격예측 모델은 필수적입니다.
- 앞서 언급한 할인율 밴드 등은 보다 적절한 구간으로 구분함으로써 성능을 개선할 여지가 있습니다. 뿐만 아니라 XGBoost, Gradient Boosting Machine, Random Forrest 등 다양하고 보다 개선된 머신러닝 알고리즘 등이 존재하므로 이들을 통해 모델을 고도화하고자 합니다.
- **누적분기를 X축으로, 할인율을 Y축으로 한, 앞서 EDA에서 본 그래프가 마치 로그 그래프의 꼴을 띄는 것으로 보여 단순히 선형회귀한 값의 오차값(MSE, MAE)이 이렇게 작은 것이 오류가 존재한 것이 아닌가 의문을 가지실 수도 있습니다. 단순히 누적분기만을 할인율에 대한 설명변수로 보았다면 그렇습니다. 하지만 이번 선형회귀에서는 책의 품질과 관련한 다양한 더미변수 고려하였습니다. 측 2차원으로 표현할 수 없는, 보다 다차원의 그래프로 관계를 갖기 때문에 높은 차수가 아닌 단순 linear regression으로도 높은 설명력을 지닌 모델을 제작할 수 있습니다. 물론 한가지 염려해야할 부분이 있습니다. 바로 과적합입니다. get_dummies 메서드를 통해 기존 6개의 책상태 변수는 필기 없음, 연필/샤프, 볼펜/형광펜으로 각각 3개씩 분기해 총 18개의 더미변수로 급증했습니다. 따라서 총 19개의 X 설명변수를 갖게 되니 높은 설명력을 갖게 된다고 볼 수도 있습니다. 하지만 test 데이터셋에도 매우 작은 오차를 가지므로 이러한 과적합에 대한 염려는 적다고 볼 수 있습니다. 추후 보다 많은 데이터를 통해 보다 강건한 모델을 제작할 필요가 있음을 시사합니다.**
- 알라딘, 예스24 등 다양한 중고책거래 플랫폼을 통해서 데이터셋을 더욱 확보할 수 있고, 단순히 대학교 교과서뿐만이 아니라 다양한 상황에서 거래되는 중고책들에 대하여 군집화 알고리즘 등을 통해 이들의 특성을 고려한 판매전략을 계획할 수 있습니다.
- 프로젝트를 진행하며 아쉬웠던 것은, 서두에 이야기했던 양질의 중고책이 버려지는 문제를 해결하기위해서는 아직 모델의 고도화를 할 부분이 많고, 매입을 자동화하는 하드웨어와 다른 소프트웨어 프로그램에 대한 설계와 구현이 필요하다는 것입니다. 우선 빠듯한 프로젝트 경진대회 기간동안만 준비하느라 부족했던 머신러닝 모델의 성능을 개선하고자 합니다. 보다 다양한 사이트에서의 중고책 거래 데이터를 웹크롤링하고, 이를 통해 보다 정밀한 중고책 가격 할인율 예측모델를 제작하는 것을 목표로 하고 있습니다. 이것이 충분이 이뤄지고 나면, 중고책 매입을 자동화하는 나머지 과정들을 수행해 환경과 경제에 도움이 되는 서비스를 완성하고 싶습니다.
